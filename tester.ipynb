{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export03/data/opt/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module torchio.transforms.augmentation.intensity.random_labels_to_image in torchio.transforms.augmentation.intensity:\n",
      "\n",
      "NAME\n",
      "    torchio.transforms.augmentation.intensity.random_labels_to_image\n",
      "\n",
      "CLASSES\n",
      "    torchio.transforms.augmentation.random_transform.RandomTransform(torchio.transforms.transform.Transform)\n",
      "        RandomLabelsToImage(torchio.transforms.augmentation.random_transform.RandomTransform, torchio.transforms.intensity_transform.IntensityTransform)\n",
      "    torchio.transforms.intensity_transform.IntensityTransform(torchio.transforms.transform.Transform)\n",
      "        LabelsToImage\n",
      "        RandomLabelsToImage(torchio.transforms.augmentation.random_transform.RandomTransform, torchio.transforms.intensity_transform.IntensityTransform)\n",
      "    \n",
      "    class LabelsToImage(torchio.transforms.intensity_transform.IntensityTransform)\n",
      "     |  LabelsToImage(label_key: str, mean: Optional[collections.abc.Sequence[float]], std: Optional[collections.abc.Sequence[float]], image_key: str = 'image_from_labels', used_labels: Optional[collections.abc.Sequence[int]] = None, ignore_background: bool = False, discretize: bool = False, **kwargs)\n",
      "     |  \n",
      "     |  Generate an image from a segmentation.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      label_key: String designating the label map in the subject\n",
      "     |          that will be used to generate the new image.\n",
      "     |      used_labels: Sequence of integers designating the labels used\n",
      "     |          to generate the new image. If categorical encoding is used,\n",
      "     |          :attr:`label_channels` refers to the values of the\n",
      "     |          categorical encoding. If one hot encoding or partial-volume\n",
      "     |          label maps are used, :attr:`label_channels` refers to the\n",
      "     |          channels of the label maps.\n",
      "     |          Default uses all labels. Missing voxels will be filled with zero\n",
      "     |          or with voxels from an already existing volume,\n",
      "     |          see :attr:`image_key`.\n",
      "     |      image_key: String designating the key to which the new volume will be\n",
      "     |          saved. If this key corresponds to an already existing volume,\n",
      "     |          missing voxels will be filled with the corresponding values\n",
      "     |          in the original volume.\n",
      "     |      mean: Sequence of means for each label.\n",
      "     |          If not ``None`` and :attr:`label_channels` is not ``None``,\n",
      "     |          :attr:`mean` and :attr:`label_channels` must have the\n",
      "     |          same length.\n",
      "     |      std: Sequence of standard deviations for each label.\n",
      "     |          If not ``None`` and :attr:`label_channels` is not ``None``,\n",
      "     |          :attr:`std` and :attr:`label_channels` must have the\n",
      "     |          same length.\n",
      "     |      discretize: If ``True``, partial-volume label maps will be discretized.\n",
      "     |          Does not have any effects if not using partial-volume label maps.\n",
      "     |          Discretization is done taking the class of the highest value per\n",
      "     |          voxel in the different partial-volume label maps using\n",
      "     |          :func:`torch.argmax()` on the channel dimension (i.e. 0).\n",
      "     |      ignore_background: If ``True``, input voxels labeled as ``0`` will not\n",
      "     |          be modified.\n",
      "     |      **kwargs: See :class:`~torchio.transforms.Transform` for additional\n",
      "     |          keyword arguments.\n",
      "     |  \n",
      "     |  .. note:: It is recommended to blur the new images to make the result more\n",
      "     |      realistic. See\n",
      "     |      :class:`~torchio.transforms.augmentation.RandomBlur`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LabelsToImage\n",
      "     |      torchio.transforms.intensity_transform.IntensityTransform\n",
      "     |      torchio.transforms.transform.Transform\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, label_key: str, mean: Optional[collections.abc.Sequence[float]], std: Optional[collections.abc.Sequence[float]], image_key: str = 'image_from_labels', used_labels: Optional[collections.abc.Sequence[int]] = None, ignore_background: bool = False, discretize: bool = False, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  apply_transform(self, subject: torchio.data.subject.Subject) -> torchio.data.subject.Subject\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  generate_tissue(data: Union[torch.Tensor, numpy.ndarray], mean: float, std: float) -> Union[torch.Tensor, numpy.ndarray]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchio.transforms.intensity_transform.IntensityTransform:\n",
      "     |  \n",
      "     |  arguments_are_dict(self) -> bool\n",
      "     |      Check if main arguments are dict.\n",
      "     |      \n",
      "     |      Return ``True`` if the type of all attributes specified in the\n",
      "     |      :attr:`args_names` have ``dict`` type.\n",
      "     |  \n",
      "     |  get_images(self, subject: torchio.data.subject.Subject) -> list\n",
      "     |  \n",
      "     |  get_images_dict(self, subject: torchio.data.subject.Subject) -> dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchio.transforms.transform.Transform:\n",
      "     |  \n",
      "     |  __call__(self, data: ~InputType) -> ~InputType\n",
      "     |      Transform data and return a result of the same type.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data: Instance of :class:`torchio.Subject`, 4D\n",
      "     |              :class:`torch.Tensor` or :class:`numpy.ndarray` with dimensions\n",
      "     |              :math:`(C, W, H, D)`, where :math:`C` is the number of channels\n",
      "     |              and :math:`W, H, D` are the spatial dimensions. If the input is\n",
      "     |              a tensor, the affine matrix will be set to identity. Other\n",
      "     |              valid input types are a SimpleITK image, a\n",
      "     |              :class:`torchio.Image`, a NiBabel Nifti1 image or a\n",
      "     |              :class:`dict`. The output type is the same as the input type.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  add_base_args(self, arguments, overwrite_on_existing: bool = False)\n",
      "     |      Add the init args to existing arguments\n",
      "     |  \n",
      "     |  add_transform_to_subject_history(self, subject)\n",
      "     |  \n",
      "     |  get_base_args(self) -> dict\n",
      "     |      Provides easy access to the arguments used to instantiate the base class\n",
      "     |      (:class:`~torchio.transforms.transform.Transform`) of any transform.\n",
      "     |      \n",
      "     |      This method is particularly useful when a new transform can be represented as a variant\n",
      "     |      of an existing transform (e.g. all random transforms), allowing for seamless instantiation\n",
      "     |      of the existing transform with the same arguments as the new transform during `apply_transform`.\n",
      "     |      \n",
      "     |      Note: The `p` argument (probability of applying the transform) is excluded to avoid\n",
      "     |      multiplying the probability of both existing and new transform.\n",
      "     |  \n",
      "     |  get_mask_from_bounds(self, bounds_parameters: Union[int, tuple[int, int, int], tuple[int, int, int, int, int, int], NoneType], tensor: torch.Tensor) -> torch.Tensor\n",
      "     |  \n",
      "     |  get_mask_from_masking_method(self, masking_method: Union[str, Callable[[torch.Tensor], torch.Tensor], int, tuple[int, int, int], tuple[int, int, int, int, int, int], NoneType], subject: torchio.data.subject.Subject, tensor: torch.Tensor, labels: Optional[collections.abc.Sequence[int]] = None) -> torch.Tensor\n",
      "     |  \n",
      "     |  inverse(self)\n",
      "     |  \n",
      "     |  is_invertible(self)\n",
      "     |  \n",
      "     |  parse_params(self, params, around, name, make_ranges=True, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torchio.transforms.transform.Transform:\n",
      "     |  \n",
      "     |  get_mask_from_anatomical_label(anatomical_label: str, tensor: torch.Tensor) -> torch.Tensor\n",
      "     |  \n",
      "     |  get_sitk_interpolator(interpolation: str) -> int\n",
      "     |  \n",
      "     |  mean(tensor: torch.Tensor) -> torch.Tensor\n",
      "     |  \n",
      "     |  nib_to_sitk(data: Union[torch.Tensor, numpy.ndarray], affine: Union[torch.Tensor, numpy.ndarray]) -> SimpleITK.SimpleITK.Image\n",
      "     |  \n",
      "     |  ones(tensor: torch.Tensor) -> torch.Tensor\n",
      "     |  \n",
      "     |  parse_bounds(bounds_parameters: Union[int, tuple[int, int, int], tuple[int, int, int, int, int, int], NoneType]) -> Optional[tuple[int, int, int, int, int, int]]\n",
      "     |  \n",
      "     |  parse_include_and_exclude_keys(include: Optional[collections.abc.Sequence[str]], exclude: Optional[collections.abc.Sequence[str]], label_keys: Optional[collections.abc.Sequence[str]]) -> tuple\n",
      "     |  \n",
      "     |  parse_interpolation(interpolation: str) -> str\n",
      "     |  \n",
      "     |  parse_probability(probability: float) -> float\n",
      "     |  \n",
      "     |  sitk_to_nib(image: SimpleITK.SimpleITK.Image) -> tuple\n",
      "     |  \n",
      "     |  to_range(n, around)\n",
      "     |  \n",
      "     |  validate_keys_sequence(keys: Optional[collections.abc.Sequence[str]], name: str) -> None\n",
      "     |      Ensure that the input is not a string but a sequence of strings.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from torchio.transforms.transform.Transform:\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torchio.transforms.transform.Transform:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RandomLabelsToImage(torchio.transforms.augmentation.random_transform.RandomTransform, torchio.transforms.intensity_transform.IntensityTransform)\n",
      "     |  RandomLabelsToImage(label_key: Optional[str] = None, used_labels: Optional[collections.abc.Sequence[int]] = None, image_key: str = 'image_from_labels', mean: Optional[collections.abc.Sequence[Union[float, tuple[float, float]]]] = None, std: Optional[collections.abc.Sequence[Union[float, tuple[float, float]]]] = None, default_mean: Union[float, tuple[float, float]] = (0.1, 0.9), default_std: Union[float, tuple[float, float]] = (0.01, 0.1), discretize: bool = False, ignore_background: bool = False, **kwargs)\n",
      "     |  \n",
      "     |  Randomly generate an image from a segmentation.\n",
      "     |  \n",
      "     |  Based on the work by Billot et al.: `A Learning Strategy for Contrast-agnostic MRI Segmentation`_\n",
      "     |  and `Partial Volume Segmentation of Brain MRI Scans of any Resolution and Contrast`_.\n",
      "     |  \n",
      "     |  .. _A Learning Strategy for Contrast-agnostic MRI Segmentation: http://proceedings.mlr.press/v121/billot20a.html\n",
      "     |  \n",
      "     |  .. _Partial Volume Segmentation of Brain MRI Scans of any Resolution and Contrast: https://link.springer.com/chapter/10.1007/978-3-030-59728-3_18\n",
      "     |  \n",
      "     |  .. plot::\n",
      "     |  \n",
      "     |      import torch\n",
      "     |      import torchio as tio\n",
      "     |      torch.manual_seed(42)\n",
      "     |      colin = tio.datasets.Colin27(2008)\n",
      "     |      label_map = colin.cls\n",
      "     |      colin.remove_image('t1')\n",
      "     |      colin.remove_image('t2')\n",
      "     |      colin.remove_image('pd')\n",
      "     |      downsample = tio.Resample(1)\n",
      "     |      blurring_transform = tio.RandomBlur(std=0.6)\n",
      "     |      create_synthetic_image = tio.RandomLabelsToImage(\n",
      "     |          image_key='synthetic',\n",
      "     |          ignore_background=True,\n",
      "     |      )\n",
      "     |      transform = tio.Compose((\n",
      "     |          downsample,\n",
      "     |          create_synthetic_image,\n",
      "     |          blurring_transform,\n",
      "     |      ))\n",
      "     |      colin_synth = transform(colin)\n",
      "     |      colin_synth.plot()\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      label_key: String designating the label map in the subject\n",
      "     |          that will be used to generate the new image.\n",
      "     |      used_labels: Sequence of integers designating the labels used\n",
      "     |          to generate the new image. If categorical encoding is used,\n",
      "     |          :attr:`label_channels` refers to the values of the\n",
      "     |          categorical encoding. If one hot encoding or partial-volume\n",
      "     |          label maps are used, :attr:`label_channels` refers to the\n",
      "     |          channels of the label maps.\n",
      "     |          Default uses all labels. Missing voxels will be filled with zero\n",
      "     |          or with voxels from an already existing volume,\n",
      "     |          see :attr:`image_key`.\n",
      "     |      image_key: String designating the key to which the new volume will be\n",
      "     |          saved. If this key corresponds to an already existing volume,\n",
      "     |          missing voxels will be filled with the corresponding values\n",
      "     |          in the original volume.\n",
      "     |      mean: Sequence of means for each label.\n",
      "     |          For each value :math:`v`, if a tuple :math:`(a, b)` is\n",
      "     |          provided then :math:`v \\sim \\mathcal{U}(a, b)`.\n",
      "     |          If ``None``, :attr:`default_mean` range will be used for every\n",
      "     |          label.\n",
      "     |          If not ``None`` and :attr:`label_channels` is not ``None``,\n",
      "     |          :attr:`mean` and :attr:`label_channels` must have the\n",
      "     |          same length.\n",
      "     |      std: Sequence of standard deviations for each label.\n",
      "     |          For each value :math:`v`, if a tuple :math:`(a, b)` is\n",
      "     |          provided then :math:`v \\sim \\mathcal{U}(a, b)`.\n",
      "     |          If ``None``, :attr:`default_std` range will be used for every\n",
      "     |          label.\n",
      "     |          If not ``None`` and :attr:`label_channels` is not ``None``,\n",
      "     |          :attr:`std` and :attr:`label_channels` must have the\n",
      "     |          same length.\n",
      "     |      default_mean: Default mean range.\n",
      "     |      default_std: Default standard deviation range.\n",
      "     |      discretize: If ``True``, partial-volume label maps will be discretized.\n",
      "     |          Does not have any effects if not using partial-volume label maps.\n",
      "     |          Discretization is done taking the class of the highest value per\n",
      "     |          voxel in the different partial-volume label maps using\n",
      "     |          :func:`torch.argmax()` on the channel dimension (i.e. 0).\n",
      "     |      ignore_background: If ``True``, input voxels labeled as ``0`` will not\n",
      "     |          be modified.\n",
      "     |      **kwargs: See :class:`~torchio.transforms.Transform` for additional\n",
      "     |          keyword arguments.\n",
      "     |  \n",
      "     |  .. tip:: It is recommended to blur the new images in order to simulate\n",
      "     |      partial volume effects at the borders of the synthetic structures. See\n",
      "     |      :class:`~torchio.transforms.augmentation.intensity.random_blur.RandomBlur`.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      >>> import torchio as tio\n",
      "     |      >>> subject = tio.datasets.ICBM2009CNonlinearSymmetric()\n",
      "     |      >>> # Using the default parameters\n",
      "     |      >>> transform = tio.RandomLabelsToImage(label_key='tissues')\n",
      "     |      >>> # Using custom mean and std\n",
      "     |      >>> transform = tio.RandomLabelsToImage(\n",
      "     |      ...     label_key='tissues', mean=[0.33, 0.66, 1.], std=[0, 0, 0]\n",
      "     |      ... )\n",
      "     |      >>> # Discretizing the partial volume maps and blurring the result\n",
      "     |      >>> simulation_transform = tio.RandomLabelsToImage(\n",
      "     |      ...     label_key='tissues', mean=[0.33, 0.66, 1.], std=[0, 0, 0], discretize=True\n",
      "     |      ... )\n",
      "     |      >>> blurring_transform = tio.RandomBlur(std=0.3)\n",
      "     |      >>> transform = tio.Compose([simulation_transform, blurring_transform])\n",
      "     |      >>> transformed = transform(subject)  # subject has a new key 'image_from_labels' with the simulated image\n",
      "     |      >>> # Filling holes of the simulated image with the original T1 image\n",
      "     |      >>> rescale_transform = tio.RescaleIntensity(\n",
      "     |      ...     out_min_max=(0, 1), percentiles=(1, 99))   # Rescale intensity before filling holes\n",
      "     |      >>> simulation_transform = tio.RandomLabelsToImage(\n",
      "     |      ...     label_key='tissues',\n",
      "     |      ...     image_key='t1',\n",
      "     |      ...     used_labels=[0, 1]\n",
      "     |      ... )\n",
      "     |      >>> transform = tio.Compose([rescale_transform, simulation_transform])\n",
      "     |      >>> transformed = transform(subject)  # subject's key 't1' has been replaced with the simulated image\n",
      "     |  \n",
      "     |  .. seealso:: :class:`~torchio.transforms.preprocessing.label.remap_labels.RemapLabels`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomLabelsToImage\n",
      "     |      torchio.transforms.augmentation.random_transform.RandomTransform\n",
      "     |      torchio.transforms.intensity_transform.IntensityTransform\n",
      "     |      torchio.transforms.transform.Transform\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, label_key: Optional[str] = None, used_labels: Optional[collections.abc.Sequence[int]] = None, image_key: str = 'image_from_labels', mean: Optional[collections.abc.Sequence[Union[float, tuple[float, float]]]] = None, std: Optional[collections.abc.Sequence[Union[float, tuple[float, float]]]] = None, default_mean: Union[float, tuple[float, float]] = (0.1, 0.9), default_std: Union[float, tuple[float, float]] = (0.01, 0.1), discretize: bool = False, ignore_background: bool = False, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  apply_transform(self, subject: torchio.data.subject.Subject) -> torchio.data.subject.Subject\n",
      "     |  \n",
      "     |  get_params(self, label: int) -> tuple\n",
      "     |  \n",
      "     |  parse_gaussian_parameters(self, params: collections.abc.Sequence, name: str) -> list\n",
      "     |  \n",
      "     |  parse_mean_and_std(self, mean: collections.abc.Sequence, std: collections.abc.Sequence) -> tuple\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  parse_gaussian_parameter(nums_range: Union[float, tuple[float, float]], name: str) -> tuple\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchio.transforms.augmentation.random_transform.RandomTransform:\n",
      "     |  \n",
      "     |  parse_degrees(self, degrees: 'TypeRangeFloat') -> 'tuple[float, float]'\n",
      "     |  \n",
      "     |  parse_translation(self, translation: 'TypeRangeFloat') -> 'tuple[float, float]'\n",
      "     |  \n",
      "     |  sample_uniform_sextet(self, params: 'TypeSextetFloat') -> 'TypeTripletFloat'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torchio.transforms.augmentation.random_transform.RandomTransform:\n",
      "     |  \n",
      "     |  sample_uniform(a: 'float', b: 'float') -> 'float'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchio.transforms.intensity_transform.IntensityTransform:\n",
      "     |  \n",
      "     |  arguments_are_dict(self) -> bool\n",
      "     |      Check if main arguments are dict.\n",
      "     |      \n",
      "     |      Return ``True`` if the type of all attributes specified in the\n",
      "     |      :attr:`args_names` have ``dict`` type.\n",
      "     |  \n",
      "     |  get_images(self, subject: torchio.data.subject.Subject) -> list\n",
      "     |  \n",
      "     |  get_images_dict(self, subject: torchio.data.subject.Subject) -> dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchio.transforms.transform.Transform:\n",
      "     |  \n",
      "     |  __call__(self, data: ~InputType) -> ~InputType\n",
      "     |      Transform data and return a result of the same type.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data: Instance of :class:`torchio.Subject`, 4D\n",
      "     |              :class:`torch.Tensor` or :class:`numpy.ndarray` with dimensions\n",
      "     |              :math:`(C, W, H, D)`, where :math:`C` is the number of channels\n",
      "     |              and :math:`W, H, D` are the spatial dimensions. If the input is\n",
      "     |              a tensor, the affine matrix will be set to identity. Other\n",
      "     |              valid input types are a SimpleITK image, a\n",
      "     |              :class:`torchio.Image`, a NiBabel Nifti1 image or a\n",
      "     |              :class:`dict`. The output type is the same as the input type.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  add_base_args(self, arguments, overwrite_on_existing: bool = False)\n",
      "     |      Add the init args to existing arguments\n",
      "     |  \n",
      "     |  add_transform_to_subject_history(self, subject)\n",
      "     |  \n",
      "     |  get_base_args(self) -> dict\n",
      "     |      Provides easy access to the arguments used to instantiate the base class\n",
      "     |      (:class:`~torchio.transforms.transform.Transform`) of any transform.\n",
      "     |      \n",
      "     |      This method is particularly useful when a new transform can be represented as a variant\n",
      "     |      of an existing transform (e.g. all random transforms), allowing for seamless instantiation\n",
      "     |      of the existing transform with the same arguments as the new transform during `apply_transform`.\n",
      "     |      \n",
      "     |      Note: The `p` argument (probability of applying the transform) is excluded to avoid\n",
      "     |      multiplying the probability of both existing and new transform.\n",
      "     |  \n",
      "     |  get_mask_from_bounds(self, bounds_parameters: Union[int, tuple[int, int, int], tuple[int, int, int, int, int, int], NoneType], tensor: torch.Tensor) -> torch.Tensor\n",
      "     |  \n",
      "     |  get_mask_from_masking_method(self, masking_method: Union[str, Callable[[torch.Tensor], torch.Tensor], int, tuple[int, int, int], tuple[int, int, int, int, int, int], NoneType], subject: torchio.data.subject.Subject, tensor: torch.Tensor, labels: Optional[collections.abc.Sequence[int]] = None) -> torch.Tensor\n",
      "     |  \n",
      "     |  inverse(self)\n",
      "     |  \n",
      "     |  is_invertible(self)\n",
      "     |  \n",
      "     |  parse_params(self, params, around, name, make_ranges=True, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torchio.transforms.transform.Transform:\n",
      "     |  \n",
      "     |  get_mask_from_anatomical_label(anatomical_label: str, tensor: torch.Tensor) -> torch.Tensor\n",
      "     |  \n",
      "     |  get_sitk_interpolator(interpolation: str) -> int\n",
      "     |  \n",
      "     |  mean(tensor: torch.Tensor) -> torch.Tensor\n",
      "     |  \n",
      "     |  nib_to_sitk(data: Union[torch.Tensor, numpy.ndarray], affine: Union[torch.Tensor, numpy.ndarray]) -> SimpleITK.SimpleITK.Image\n",
      "     |  \n",
      "     |  ones(tensor: torch.Tensor) -> torch.Tensor\n",
      "     |  \n",
      "     |  parse_bounds(bounds_parameters: Union[int, tuple[int, int, int], tuple[int, int, int, int, int, int], NoneType]) -> Optional[tuple[int, int, int, int, int, int]]\n",
      "     |  \n",
      "     |  parse_include_and_exclude_keys(include: Optional[collections.abc.Sequence[str]], exclude: Optional[collections.abc.Sequence[str]], label_keys: Optional[collections.abc.Sequence[str]]) -> tuple\n",
      "     |  \n",
      "     |  parse_interpolation(interpolation: str) -> str\n",
      "     |  \n",
      "     |  parse_probability(probability: float) -> float\n",
      "     |  \n",
      "     |  sitk_to_nib(image: SimpleITK.SimpleITK.Image) -> tuple\n",
      "     |  \n",
      "     |  to_range(n, around)\n",
      "     |  \n",
      "     |  validate_keys_sequence(keys: Optional[collections.abc.Sequence[str]], name: str) -> None\n",
      "     |      Ensure that the input is not a string but a sequence of strings.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from torchio.transforms.transform.Transform:\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torchio.transforms.transform.Transform:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    Optional = typing.Optional\n",
      "        Optional type.\n",
      "        \n",
      "        Optional[X] is equivalent to Union[X, None].\n",
      "    \n",
      "    TypeData = typing.Union[torch.Tensor, numpy.ndarray]\n",
      "    TypeRangeFloat = typing.Union[float, tuple[float, float]]\n",
      "\n",
      "FILE\n",
      "    /export03/data/opt/venv/lib/python3.9/site-packages/torchio/transforms/augmentation/intensity/random_labels_to_image.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torchio.transforms.augmentation.intensity.random_labels_to_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
